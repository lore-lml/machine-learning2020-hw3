{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Install Requirements**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torch.backends import cudnn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from pacs_dataset import Pacs\n",
    "from dann import alexdann\n",
    "from dann import train_src, test_target\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Set Arguments**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "BATCH_SIZE = 128     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
    "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
    "\n",
    "LR = 3e-5          # The initial Learning Rate\n",
    "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
    "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
    "\n",
    "NUM_EPOCHS = 15      # Total number of training epochs (iterations over dataset)\n",
    "STEP_SIZE = 15       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
    "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
    "\n",
    "LOG_FREQUENCY = 10\n",
    "\n",
    "BASE_FILE_PATH = \"DA_RUN18_LR3e-5_ADAMW_EP15_SS15_G01_ALL_TRANSF\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Define Data Preprocessing**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
    "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
    "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
    "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
    "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
    "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) # Normalizes tensor with mean and standard deviation\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Prepare Dataset**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "# classes source_data: 7\n",
      "# classes val_set: 7\n",
      "source_data: 1670 elements\n",
      "target_data: 2048 elements\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "ROOT = 'PACS'\n",
    "\n",
    "source_data = Pacs(ROOT, transform=transforms, source='photo')\n",
    "target_data = Pacs(ROOT, transform=transforms, source='art_painting')\n",
    "\n",
    "_, source_labels = source_data.get_img_with_labels()\n",
    "_, target_labels = target_data.get_img_with_labels()\n",
    "\n",
    "print(f\"# classes source_data: {len(set(source_labels))}\")\n",
    "print(f\"# classes val_set: {len(set(target_labels))}\")\n",
    "print(f\"source_data: {len(source_data)} elements\")\n",
    "print(f\"target_data: {len(target_data)} elements\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Prepare Dataloaders**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "source_dataloader = DataLoader(source_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "target_dataloader = DataLoader(target_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Prepare Network**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-767b699311de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdann\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malexdann\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_cnn_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdann\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"******* NET CREATED *******\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alexdann' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'alexdann' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "def init_cnn_objects(model):\n",
    "  \n",
    "  # Define loss function\n",
    "  criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
    "  parameters_to_optimize = model.parameters() # In this case we optimize over all the parameters of AlexNet\n",
    "  \n",
    "  #optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "  #optimizer = optim.Adam(parameters_to_optimize, lr=LR,amsgrad=True)\n",
    "  optimizer = optim.AdamW(parameters_to_optimize, lr=LR,amsgrad=True, weight_decay=WEIGHT_DECAY)\n",
    "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "  return criterion, optimizer, scheduler\n",
    "\n",
    "dann = alexdann(pretrained=True)\n",
    "criterion, optimizer, scheduler = init_cnn_objects(dann)\n",
    "print(\"******* NET CREATED *******\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def simple_train_test(model, source_dataloader, target_dataloader, file_path=BASE_FILE_PATH):\n",
    "    train_losses = []\n",
    "    loss_min = -1\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "    cudnn.benchmark\n",
    "    \n",
    "    current_step = 0\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
    "        cumulative_loss = train_src(model, source_dataloader, optimizer, criterion, scheduler, current_step, DEVICE)\n",
    "        curr_loss = cumulative_loss / len(source_dataloader)\n",
    "        train_losses.append(curr_loss)\n",
    "        if loss_min == -1 or loss_min > curr_loss:\n",
    "            loss_min = curr_loss\n",
    "            torch.save(model, f\"{file_path}_best_model.pth\")\n",
    "        scheduler.step()\n",
    "        \n",
    "    \n",
    "    accuracy = test_target(model, target_dataloader, criterion, DEVICE) / float(len(target_data))\n",
    "    print(f\"Accuracy on test set: {accuracy}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}